<style>
  /* Audio visualization styles */
  #audio-visualizer {
    display: flex;
    align-items: end;
    gap: 2px;
    height: 20px;
  }

  /* Pulse animation for recording indicator */
  @keyframes pulse {
    0% {
      opacity: 1;
    }

    50% {
      opacity: 0.5;
    }

    100% {
      opacity: 1;
    }
  }

  .animate-pulse {
    animation: pulse 1.5s infinite;
  }

  /* Audio message styling */
  .auto-play-audio {
    /* Styles for auto-play audio elements */
  }
</style>
<div
  id="chatarea-{{ chat.sender_id }}"
  class="w-screen md:w-[500px] 2xl:w-[750px] flex flex-col gap-[10px] h-full overflow-hidden border-x border-[var(--border-color)]"
>
  <div
    class="h-[50px] bg-[var(--sec-bg-color)] flex md:hidden flex-row items-center justify-between px-[21px] py-[16px]"
  >
    <a href="/admin/facebook"
      ><i
        data-lucide="chevron-left"
        class="text-[var(--main-color)] hover:cursor-pointer"
      ></i
    ></a>
    <p class="text-[var(--sec-text)] font-bold">
      {{ chat.user_info.first_name or chat.sender_id }} {% if
      chat.user_info.last_name %} {{ chat.user_info.last_name }} {% endif %}
    </p>
    <p
      id="toggleClientInfo"
      class="text-[var(--main-color)] font-bold text-[14px] cursor-pointer"
    >
      Client Info
    </p>
  </div>
  <div
    id="messageArea"
    class="flex flex-col gap-[20px] w-full overflow-y-auto flex-grow pt-[20px] px-[20px] md:px-[40px]"
  >
    {% for message in chat.messages %} {% include 'components/fb-message.html'
    %} {% endfor %}
  </div>
  {% if chat.admin_enabled %}
  <div
    class="relative w-full h-[60px] px-[20px] md:px-[40px] mb-[20px] flex gap-2"
  >
    <form
      class="relative w-full h-[60px]"
      hx-post="/admin/facebook/{{ chat.sender_id }}/send_message"
      hx-trigger="submit"
      hx-swap="none"
      onsubmit="return !!this.message.value.trim()"
      hx-on::after-request="this.reset(); checkInputValue(); location.reload()"
      id="messageForm"
    >
      <input
        rows="1"
        placeholder="Send a message..."
        class="w-full border-2 border-[var(--border-color)] transition-all duration-300 focus:border-[var(--main-color)] rounded-[5px] h-[60px] resize-none overflow-x-auto overflow-y-hidden whitespace-nowrap focus:outline-none p-[19px] pr-[80px] text-[16px] leading-[22px]"
        name="message"
        id="message"
        required
        onkeyup="handleKeyPress(event); checkInputValue()"
      />
      <button
        type="submit"
        id="send-btn"
        class="bg-[var(--main-color)] text-[var(--white)] hover:opacity-90 transition-opacity px-[2px] py-[1px] absolute right-[8px] bottom-[8px] flex items-center justify-center w-[44px] h-[44px] rounded-[5px] focus:outline-none cursor-not-allowed opacity-70"
      >
        <i data-lucide="corner-down-left" class="text-[var(--white)]"></i>
      </button>
    </form>

    <!-- Microphone Button -->
    <div
      id="enable-mic"
      class="flex items-center justify-center w-[60px] h-[60px] rounded-[5px] border-2 border-[var(--border-color)] hover:border-[var(--main-color)] transition-all duration-300 cursor-pointer bg-[var(--sec-bg-color)]"
      title="Record Audio"
      onclick="enableMic()"
    >
      <svg
        xmlns="http://www.w3.org/2000/svg"
        width="24"
        height="24"
        viewBox="0 0 24 24"
        fill="none"
        stroke="currentColor"
        stroke-width="2"
        stroke-linecap="round"
        stroke-linejoin="round"
        class="lucide lucide-mic text-[var(--main-color)]"
      >
        <path d="M12 19v3" />
        <path d="M19 10v2a7 7 0 0 1-14 0v-2" />
        <rect x="9" y="2" width="6" height="13" rx="3" />
      </svg>
    </div>
  </div>
  {% else %}
  <!-- Jump In button -->
  <div class="relative w-full h-[40px] px-[20px] md:px-[40px] mb-[20px]">
    <div
      class="flex h-full bg-[var(--main-color)] rounded-md hover:opacity-90 duration-300 transition-all items-center justify-center py-4 cursor-pointer"
      hx-post="/admin/facebook/{{chat.sender_id}}/intervene"
      hx-on::after-request="location.reload()"
      hx-swap="none"
      hx-trigger="click"
    >
      <p class="font-bold text-white">Jump In</p>
    </div>
  </div>
  {% endif %}
</div>
<script>
  // Audio recording variables
  let mediaRecorder = null;
  let audioChunks = [];
  let isRecording = false;
  let audioContext = null;
  let analyser = null;
  let microphone = null;
  let javascriptNode = null;

  // Enable/disable mic function
  function enableMic() {
    console.log("Enable Mic");
    const micButton = document.getElementById("enable-mic");
    const messageInput = document.getElementById("message");
    const sendBtn = document.getElementById("send-btn");

    if (!isRecording) {
      startRecording(micButton, messageInput, sendBtn);
    } else {
      stopRecording(micButton, messageInput, sendBtn);
    }
  }

  // Start recording function
  function startRecording(micButton, messageInput, sendBtn) {
    // Change icon to square (stop)
    const micSvg = micButton.querySelector("svg");
    if (micSvg) {
      micSvg.outerHTML = `
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-square text-[var(--main-color)]">
                <rect width="18" height="18" x="3" y="3" rx="2" ry="2"/>
            </svg>
        `;
    }

    // Hide message input and show audio feedback
    messageInput.style.display = "none";
    createAudioFeedback();

    // Disable send button
    sendBtn.style.cursor = "not-allowed";
    sendBtn.style.opacity = "0.5";

    // Start recording process
    startAudioRecording();
  }

  // Stop recording function
  function stopRecording(micButton, messageInput, sendBtn) {
    // Change icon back to mic
    const squareSvg = micButton.querySelector("svg");
    if (squareSvg) {
      squareSvg.outerHTML = `
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mic text-[var(--main-color)]">
                <path d="M12 19v3"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><rect x="9" y="2" width="6" height="13" rx="3"/>
            </svg>
        `;
    }

    // Remove audio feedback and show message input
    removeAudioFeedback();
    messageInput.style.display = "block";

    // Re-enable send button if input has content
    checkInputValue();

    // Stop recording and send audio
    stopAudioRecording();
  }

  // Create audio feedback visualization
  function createAudioFeedback() {
    const form = document.getElementById("messageForm");

    const audioFeedback = document.createElement("div");
    audioFeedback.id = "audio-feedback";
    audioFeedback.className =
      "flex items-center p-4 border-2 border-[var(--main-color)] rounded-[5px] bg-[var(--sec-bg-color)] text-[var(--text-color)] text-sm w-full h-[60px]";

    audioFeedback.innerHTML = `
        <div id="recording-indicator" class="flex items-center gap-3 w-full">
            <div class="flex items-center gap-2">
                <span class="w-3 h-3 bg-red-500 rounded-full animate-pulse"></span>
                <span>Recording...</span>
            </div>
            <div id="audio-visualizer" class="flex items-end gap-1 h-5 ml-auto"></div>
        </div>
    `;

    form.parentNode.insertBefore(audioFeedback, form);
  }

  // Remove audio feedback
  function removeAudioFeedback() {
    const audioFeedback = document.getElementById("audio-feedback");
    if (audioFeedback) {
      audioFeedback.remove();
    }
  }

  // Start audio recording with visualization
  function startAudioRecording() {
    audioChunks = [];

    navigator.mediaDevices
      .getUserMedia({ audio: true })
      .then((stream) => {
        // Set up audio context for visualization
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        microphone = audioContext.createMediaStreamSource(stream);
        javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

        analyser.smoothingTimeConstant = 0.8;
        analyser.fftSize = 1024;

        microphone.connect(analyser);
        analyser.connect(javascriptNode);
        javascriptNode.connect(audioContext.destination);

        // Set up audio visualization
        setupAudioVisualization();

        // Set up media recorder
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.ondataavailable = (event) => {
          audioChunks.push(event.data);
        };

        mediaRecorder.onstop = () => {
          // Clean up audio context
          if (javascriptNode) javascriptNode.disconnect();
          if (analyser) analyser.disconnect();
          if (microphone) microphone.disconnect();
          if (audioContext) audioContext.close();

          // Stop all tracks
          stream.getTracks().forEach((track) => track.stop());

          // Send audio to server
          sendAudioToServer();
        };

        // Start recording
        mediaRecorder.start();
        isRecording = true;
      })
      .catch((error) => {
        console.error("Error accessing microphone:", error);
        alert("Unable to access microphone. Please check your permissions.");
        resetUI();
      });
  }

  // Set up audio visualization
  function setupAudioVisualization() {
    const visualizer = document.getElementById("audio-visualizer");
    visualizer.innerHTML = "";

    // Create bars for visualization
    for (let i = 0; i < 10; i++) {
      const bar = document.createElement("div");
      bar.className =
        "w-1 bg-[var(--main-color)] rounded transition-all duration-100";
      bar.style.height = "4px";
      visualizer.appendChild(bar);
    }

    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    javascriptNode.onaudioprocess = () => {
      analyser.getByteFrequencyData(dataArray);

      // Calculate average volume
      let sum = 0;
      for (let i = 0; i < bufferLength; i++) {
        sum += dataArray[i];
      }
      const average = sum / bufferLength;

      // Update visualization bars
      const bars = visualizer.children;
      for (let i = 0; i < bars.length; i++) {
        const height = Math.max(
          Math.min(20, (average / 128) * 20 * (1 + Math.sin(i) * 0.3)) * 5,
          4,
        );
        bars[i].style.height = `${height}px`;
      }
    };
  }

  // Stop audio recording
  function stopAudioRecording() {
    if (mediaRecorder && isRecording) {
      mediaRecorder.stop();
      isRecording = false;
    }
  }

  // Send audio to server
  function sendAudioToServer() {
    if (audioChunks.length === 0) {
      console.error("No audio data to send");
      return;
    }

    const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
    const formData = new FormData();
    formData.append("audio", audioBlob, "recording.wav");

    fetch("/admin/facebook/{{ chat.sender_id }}/send_audio", {
      method: "POST",
      body: formData,
      credentials: "include",
    })
      .then((response) => {
        if (!response.ok) {
          throw new Error("Network response was not ok");
        }

        location.reload();
        scrollToBottom();
      })
      .catch((error) => {
        console.error("Error sending audio:", error);
        alert("Failed to send audio message. Please try again.");
      });
  }

  // Reset UI in case of errors
  function resetUI() {
    const micButton = document.getElementById("enable-mic");
    const messageInput = document.getElementById("message");
    const sendBtn = document.getElementById("send-btn");

    // Reset mic button - change back to mic icon
    const currentSvg = micButton.querySelector("svg");
    if (currentSvg) {
      currentSvg.outerHTML = `
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mic text-[var(--main-color)]">
                <path d="M12 19v3"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><rect x="9" y="2" width="6" height="13" rx="3"/>
            </svg>
        `;
    }

    // Remove audio feedback and show message input
    removeAudioFeedback();
    messageInput.style.display = "block";

    // Reset send button
    checkInputValue();

    isRecording = false;
  }

  // Input validation functions
  function checkInputValue() {
    const messageInput = document.getElementById("message");
    const sendBtn = document.getElementById("send-btn");
    if (messageInput.value.trim() !== "") {
      sendBtn.style.cursor = "pointer";
      sendBtn.style.opacity = "1";
    } else {
      sendBtn.style.cursor = "not-allowed";
      sendBtn.style.opacity = "0.7";
    }
  }

  function handleKeyPress(event) {
    if (
      event.key === "Enter" &&
      document.getElementById("message").value.trim() !== ""
    ) {
      document.getElementById("messageForm").requestSubmit();
    }
  }

  // Scroll to bottom function
  function scrollToBottom() {
    const messageArea = document.getElementById("messageArea");
    if (messageArea) {
      messageArea.lastElementChild?.scrollIntoView({ behavior: "smooth" });
    }
  }

  // Initialize on page load
  document.addEventListener("DOMContentLoaded", function () {
    checkInputValue();
    scrollToBottom();
    // Refresh Lucide icons
    if (typeof lucide !== "undefined") {
      lucide.createIcons();
    }
  });
</script>
